{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력값 1개, 출력값 1개: y = w1 * X1 + bias\n",
    "### 입력값 2개, 출력값 1개: y = w1 * X1 + w2 * X2 + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %autosave 0 \n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential  # class\n",
    "from tensorflow.keras.models import load_model  # model 파일 로딩\n",
    "from tensorflow.keras.layers import Dense       # 전결합층\n",
    "from tensorflow.keras.optimizers import Adam    # 가중치, bias 최적화\n",
    "from tensorflow.keras.utils import plot_model   # 네트워크 입출력 시각화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "rc('font', family='Malgun Gothic')\n",
    "\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "[[ 1 10]\n",
      " [ 2 10]\n",
      " [ 3 10]\n",
      " [ 4 10]\n",
      " [ 5 10]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = []\n",
    "for i in range(1, 101):\n",
    "    x_train.append([i, 10])\n",
    "\n",
    "x_train = np.array(x_train)    \n",
    "print(x_train.shape)\n",
    "print(x_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "[[ 68.]\n",
      " [143.]\n",
      " [218.]\n",
      " [293.]\n",
      " [368.]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 -> 실제값, Target\n",
    "# 1, 10 -> 68.0  2, 10 -> 143.0  3, 10 -> 218.0\n",
    "y_train = []\n",
    "for i in range(len(x_train)):\n",
    "    target = x_train[i][0] * x_train[i][1] / 2 * 5 * 3 - 7\n",
    "    # print(target)\n",
    "    y_train.append([target])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 12484875.4722 - val_loss: 33567484.0000\n",
      "Epoch 2/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6366382.6574 - val_loss: 12483637.0000\n",
      "Epoch 3/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2185142.9136 - val_loss: 1612948.8750\n",
      "Epoch 4/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 168924.9625 - val_loss: 308479.8750\n",
      "Epoch 5/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 89610.3471 - val_loss: 181866.1562\n",
      "Epoch 6/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 86913.9990 - val_loss: 157417.9062\n",
      "Epoch 7/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 76769.3153 - val_loss: 150915.5938\n",
      "Epoch 8/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 63501.1184 - val_loss: 134474.1875\n",
      "Epoch 9/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 54086.6290 - val_loss: 105128.7500\n",
      "Epoch 10/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 39032.2000 - val_loss: 107023.9141\n",
      "Epoch 11/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 40911.5281 - val_loss: 77588.4531\n",
      "Epoch 12/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 30650.9843 - val_loss: 80801.7344\n",
      "Epoch 13/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31000.5762 - val_loss: 53778.5508\n",
      "Epoch 14/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23713.1647 - val_loss: 42512.7109\n",
      "Epoch 15/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17641.6535 - val_loss: 51822.3047\n",
      "Epoch 16/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 12060.8456 - val_loss: 17391.1191\n",
      "Epoch 17/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 12646.7000 - val_loss: 15939.8906\n",
      "Epoch 18/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8736.8072 - val_loss: 7883.8999\n",
      "Epoch 19/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6257.1372 - val_loss: 8338.4629\n",
      "Epoch 20/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3813.9179 - val_loss: 12542.8447\n",
      "Epoch 21/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3345.8230 - val_loss: 4772.7578\n",
      "Epoch 22/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2169.8502 - val_loss: 2187.1133\n",
      "Epoch 23/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1942.0941 - val_loss: 1741.4476\n",
      "Epoch 24/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 877.5163 - val_loss: 3210.7690\n",
      "Epoch 25/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 848.5325 - val_loss: 913.8517\n",
      "Epoch 26/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 394.6154 - val_loss: 936.1780\n",
      "Epoch 27/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 350.2160 - val_loss: 694.6434\n",
      "Epoch 28/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 158.6411 - val_loss: 416.7854\n",
      "Epoch 29/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 148.3044 - val_loss: 227.0070\n",
      "Epoch 30/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 68.1960 - val_loss: 188.0477\n",
      "Epoch 31/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 40.6024 - val_loss: 69.4522\n",
      "Epoch 32/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.0729 - val_loss: 15.2785\n",
      "Epoch 33/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 11.4817 - val_loss: 20.3267\n",
      "Epoch 34/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.5005 - val_loss: 7.7959\n",
      "Epoch 35/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.7857 - val_loss: 2.6159\n",
      "Epoch 36/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7130 - val_loss: 1.8044\n",
      "Epoch 37/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.7094 - val_loss: 0.9569\n",
      "Epoch 38/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4664 - val_loss: 0.7547\n",
      "Epoch 39/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.2384\n",
      "Epoch 40/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0651\n",
      "Epoch 41/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0161\n",
      "Epoch 42/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0045\n",
      "Epoch 43/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0029\n",
      "Epoch 44/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 8.3361e-04\n",
      "Epoch 45/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.7829e-04 - val_loss: 3.8273e-04\n",
      "Epoch 46/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7948e-04 - val_loss: 4.3545e-04\n",
      "Epoch 47/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0170e-04 - val_loss: 1.3378e-04\n",
      "Epoch 48/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.3279e-05 - val_loss: 5.7244e-05\n",
      "Epoch 49/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.8686e-06 - val_loss: 6.1989e-06\n",
      "Epoch 50/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.8220e-06 - val_loss: 9.8944e-06\n",
      "Epoch 51/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2837e-06 - val_loss: 7.5102e-06\n",
      "Epoch 52/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8371e-06 - val_loss: 6.0201e-06\n",
      "Epoch 53/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2692e-06 - val_loss: 2.7657e-06\n",
      "Epoch 54/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.1721e-07 - val_loss: 2.7657e-06\n",
      "Epoch 55/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.1379e-07 - val_loss: 1.8954e-06\n",
      "Epoch 56/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.8601e-07 - val_loss: 2.6822e-06\n",
      "Epoch 57/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.7501e-07 - val_loss: 2.6822e-06\n",
      "Epoch 58/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.7501e-07 - val_loss: 1.4305e-06\n",
      "Epoch 59/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.8621e-07 - val_loss: 1.7166e-06\n",
      "Epoch 60/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.0189e-07 - val_loss: 1.7166e-06\n",
      "Epoch 61/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7216e-07 - val_loss: 1.5736e-06\n",
      "Epoch 62/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.7275e-07 - val_loss: 7.6294e-07\n",
      "Epoch 63/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0186e-07 - val_loss: 8.9407e-07\n",
      "Epoch 64/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7358e-07 - val_loss: 8.5831e-07\n",
      "Epoch 65/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2519e-07 - val_loss: 8.2254e-07\n",
      "Epoch 66/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8450e-07 - val_loss: 6.4373e-07\n",
      "Epoch 67/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8447e-07 - val_loss: 7.5102e-07\n",
      "Epoch 68/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4036e-07 - val_loss: 7.5102e-07\n",
      "Epoch 69/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.3239e-07 - val_loss: 8.9407e-07\n",
      "Epoch 70/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2618e-07 - val_loss: 3.3379e-07\n",
      "Epoch 71/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.7384e-08 - val_loss: 4.8876e-07\n",
      "Epoch 72/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1982e-07 - val_loss: 4.5300e-07\n",
      "Epoch 73/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1335e-07 - val_loss: 3.9339e-07\n",
      "Epoch 74/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1335e-07 - val_loss: 5.3644e-07\n",
      "Epoch 75/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1237e-07 - val_loss: 3.0994e-07\n",
      "Epoch 76/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1091e-07 - val_loss: 2.7418e-07\n",
      "Epoch 77/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.3989e-08 - val_loss: 2.0266e-07\n",
      "Epoch 78/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.8695e-08 - val_loss: 2.0266e-07\n",
      "Epoch 79/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.6285e-08 - val_loss: 1.5497e-07\n",
      "Epoch 80/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.6516e-08 - val_loss: 2.0266e-07\n",
      "Epoch 81/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.4426e-08 - val_loss: 8.3447e-08\n",
      "Epoch 82/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.6479e-08 - val_loss: 8.3447e-08\n",
      "Epoch 83/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.0173e-08 - val_loss: 9.5367e-08\n",
      "Epoch 84/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9981e-08 - val_loss: 8.3447e-08\n",
      "Epoch 85/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9859e-08 - val_loss: 1.1921e-07\n",
      "Epoch 86/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.2940e-08 - val_loss: 1.0729e-07\n",
      "Epoch 87/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.5361e-08 - val_loss: 9.5367e-08\n",
      "Epoch 88/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8731e-08 - val_loss: 1.4305e-07\n",
      "Epoch 89/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4168e-08 - val_loss: 9.5367e-08\n",
      "Epoch 90/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.1181e-08 - val_loss: 1.4305e-07\n",
      "Epoch 91/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9831e-08 - val_loss: 9.5367e-08\n",
      "Epoch 92/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.2486e-08 - val_loss: 9.5367e-08\n",
      "Epoch 93/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9696e-08 - val_loss: 1.4305e-07\n",
      "Epoch 94/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.7560e-08 - val_loss: 9.5367e-08\n",
      "Epoch 95/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9794e-08 - val_loss: 9.5367e-08\n",
      "Epoch 96/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.7926e-08 - val_loss: 8.3447e-08\n",
      "Epoch 97/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1069e-08 - val_loss: 8.3447e-08\n",
      "Epoch 98/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3392e-08 - val_loss: 9.5367e-08\n",
      "Epoch 99/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7533e-08 - val_loss: 8.3447e-08\n",
      "Epoch 100/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3119e-08 - val_loss: 8.3447e-08\n",
      "Epoch 101/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9846e-08 - val_loss: 1.3113e-07\n",
      "Epoch 102/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.9436e-08 - val_loss: 8.3447e-08\n",
      "Epoch 103/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.3704e-08 - val_loss: 1.0729e-07\n",
      "Epoch 104/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.0929e-08 - val_loss: 5.3883e-06\n",
      "Epoch 105/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2586e-06 - val_loss: 1.3530e-05\n",
      "Epoch 106/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4567e-06 - val_loss: 1.8001e-06\n",
      "Epoch 107/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.3974e-07 - val_loss: 2.5034e-07\n",
      "Epoch 108/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.6180e-07 - val_loss: 1.4305e-07\n",
      "Epoch 109/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7656e-07 - val_loss: 3.7074e-06\n",
      "Epoch 110/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2332e-06 - val_loss: 5.7507e-05\n",
      "Epoch 111/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4336e-05 - val_loss: 3.9959e-05\n",
      "Epoch 112/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.4196e-06 - val_loss: 8.4758e-06\n",
      "Epoch 113/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1525e-06 - val_loss: 2.0385e-06\n",
      "Epoch 114/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.4324e-07 - val_loss: 1.3113e-06\n",
      "Epoch 115/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0142e-06 - val_loss: 1.2040e-06\n",
      "Epoch 116/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.6806e-07 - val_loss: 1.2398e-06\n",
      "Epoch 117/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.5870e-06 - val_loss: 0.0015\n",
      "Epoch 118/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.4069e-04 - val_loss: 2.5367e-04\n",
      "Epoch 119/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 120/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.4437e-04 - val_loss: 0.0463\n",
      "Epoch 121/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.3483\n",
      "Epoch 122/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1105 - val_loss: 0.1907\n",
      "Epoch 123/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0672 - val_loss: 0.2683\n",
      "Epoch 124/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2656 - val_loss: 16.5957\n",
      "Epoch 125/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 22.3317 - val_loss: 171.8780\n",
      "Epoch 126/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 15.4110 - val_loss: 0.0999\n",
      "Epoch 127/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.2475 - val_loss: 78.9143\n",
      "Epoch 128/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 18.8307 - val_loss: 24.5106\n",
      "Epoch 129/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 226.9549 - val_loss: 11369.2666\n",
      "Epoch 130/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 934.7884 - val_loss: 50.6709\n",
      "Epoch 131/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7097 - val_loss: 0.3672\n",
      "Epoch 132/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 2.8776e-04\n",
      "Epoch 133/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0739e-05 - val_loss: 3.8266e-06\n",
      "Epoch 134/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7355e-06 - val_loss: 1.5497e-07\n",
      "Epoch 135/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.2396e-08 - val_loss: 1.5497e-07\n",
      "Epoch 136/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.7033e-08 - val_loss: 1.5497e-07\n",
      "Epoch 137/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5589e-07 - val_loss: 5.8651e-06\n",
      "Epoch 138/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.6082e-07 - val_loss: 3.5524e-06\n",
      "Epoch 139/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0590e-06 - val_loss: 2.1470e-05\n",
      "Epoch 140/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9392e-05 - val_loss: 1.0241e-04\n",
      "Epoch 141/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0996e-04 - val_loss: 1.5497e-07\n",
      "Epoch 142/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3780e-05 - val_loss: 4.1485e-06\n",
      "Epoch 143/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6990e-06 - val_loss: 1.2398e-06\n",
      "Epoch 144/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8743e-06 - val_loss: 1.4067e-06\n",
      "Epoch 145/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.9613e-07 - val_loss: 1.5140e-06\n",
      "Epoch 146/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.3352e-06 - val_loss: 3.7181e-05\n",
      "Epoch 147/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.1196e-05 - val_loss: 1.9916e-04\n",
      "Epoch 148/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 5.0673e-05 - val_loss: 2.4676e-06\n",
      "Epoch 149/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1775e-06 - val_loss: 1.2064e-05\n",
      "Epoch 150/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2323e-06 - val_loss: 1.5020e-05\n",
      "Epoch 151/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6517e-06 - val_loss: 1.0073e-05\n",
      "Epoch 152/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.1950e-07 - val_loss: 3.8624e-06\n",
      "Epoch 153/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.5743e-07 - val_loss: 1.9908e-06\n",
      "Epoch 154/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4545e-04 - val_loss: 0.0033\n",
      "Epoch 155/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.6423\n",
      "Epoch 156/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1508 - val_loss: 73.3890\n",
      "Epoch 157/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 86.3883 - val_loss: 31.1010\n",
      "Epoch 158/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 26.4376 - val_loss: 162.5885\n",
      "Epoch 159/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 42.0636 - val_loss: 20.2737\n",
      "Epoch 160/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 12.7564 - val_loss: 110.2370\n",
      "Epoch 161/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 46.6060 - val_loss: 8.5689\n",
      "Epoch 162/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 11.8648 - val_loss: 664.4566\n",
      "Epoch 163/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 61.2444 - val_loss: 17.0228\n",
      "Epoch 164/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.8900 - val_loss: 0.4365\n",
      "Epoch 165/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3285 - val_loss: 0.1328\n",
      "Epoch 166/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0526\n",
      "Epoch 167/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.9173\n",
      "Epoch 168/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2366 - val_loss: 0.3444\n",
      "Epoch 169/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8217 - val_loss: 72.0126\n",
      "Epoch 170/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 236.7965 - val_loss: 6.9072\n",
      "Epoch 171/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.1848 - val_loss: 0.0916\n",
      "Epoch 172/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.8095 - val_loss: 2.4930\n",
      "Epoch 173/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5706 - val_loss: 0.5383\n",
      "Epoch 174/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0703\n",
      "Epoch 175/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1442 - val_loss: 0.1412\n",
      "Epoch 176/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0666\n",
      "Epoch 177/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2185 - val_loss: 2.3410\n",
      "Epoch 178/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6809 - val_loss: 9.4963e-04\n",
      "Epoch 179/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1413 - val_loss: 20.9485\n",
      "Epoch 180/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 14.7837 - val_loss: 28.0059\n",
      "Epoch 181/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 38.3238 - val_loss: 139.0506\n",
      "Epoch 182/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 256.0563 - val_loss: 244.1316\n",
      "Epoch 183/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 44.2061 - val_loss: 62.1267\n",
      "Epoch 184/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 19.6257 - val_loss: 0.2776\n",
      "Epoch 185/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2181 - val_loss: 4.3019\n",
      "Epoch 186/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 222.4491 - val_loss: 717.7391\n",
      "Epoch 187/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 262.6544 - val_loss: 2.6032\n",
      "Epoch 188/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.7835 - val_loss: 0.0061\n",
      "Epoch 189/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.7092e-04 - val_loss: 1.8901e-04\n",
      "Epoch 190/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.5695e-06 - val_loss: 4.1723e-07\n",
      "Epoch 191/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0159e-07 - val_loss: 1.5783e-05\n",
      "Epoch 192/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.4342e-06 - val_loss: 3.5417e-05\n",
      "Epoch 193/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4545e-05 - val_loss: 7.7319e-05\n",
      "Epoch 194/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.9933e-05 - val_loss: 6.0606e-05\n",
      "Epoch 195/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3477e-06 - val_loss: 4.1151e-05\n",
      "Epoch 196/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.2851e-05 - val_loss: 0.0142\n",
      "Epoch 197/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.5148e-04 - val_loss: 6.9189e-05\n",
      "Epoch 198/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6104e-05 - val_loss: 1.4997e-05\n",
      "Epoch 199/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.9318e-07 - val_loss: 9.4175e-07\n",
      "Epoch 200/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.0764e-07 - val_loss: 5.4359e-06\n",
      "Epoch 201/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.8366e-06 - val_loss: 4.9562e-04\n",
      "Epoch 202/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8149e-04 - val_loss: 1.8042e-04\n",
      "Epoch 203/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.6931e-04 - val_loss: 0.0017\n",
      "Epoch 204/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3040 - val_loss: 36.9957\n",
      "Epoch 205/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 10.4221 - val_loss: 294.9883\n",
      "Epoch 206/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 262.6047 - val_loss: 5099.7959\n",
      "Epoch 207/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 924.9099 - val_loss: 10.0578\n",
      "Epoch 208/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 134.1720 - val_loss: 0.0966\n",
      "Epoch 209/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.0092\n",
      "Epoch 210/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.8332e-04 - val_loss: 8.7500e-06\n",
      "Epoch 211/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5218e-06 - val_loss: 1.9431e-06\n",
      "Epoch 212/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.3357e-07 - val_loss: 1.9073e-07\n",
      "Epoch 213/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.0463e-08 - val_loss: 1.7881e-07\n",
      "Epoch 214/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3556e-07 - val_loss: 3.2187e-07\n",
      "Epoch 215/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.1040e-08 - val_loss: 2.1458e-07\n",
      "Epoch 216/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.1472e-07 - val_loss: 2.4676e-06\n",
      "Epoch 217/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.8496e-07 - val_loss: 1.3113e-07\n",
      "Epoch 218/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.8610e-07 - val_loss: 2.4319e-06\n",
      "Epoch 219/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.8742e-06 - val_loss: 9.5367e-07\n",
      "Epoch 220/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.2652e-07 - val_loss: 3.0637e-06\n",
      "Epoch 221/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2441e-05 - val_loss: 3.0506e-05\n",
      "Epoch 222/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4700e-06 - val_loss: 4.9138e-05\n",
      "Epoch 223/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2971e-05 - val_loss: 1.8251e-05\n",
      "Epoch 224/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2762e-05 - val_loss: 2.4903e-05\n",
      "Epoch 225/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1518e-05 - val_loss: 1.5497e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.7646e-07 - val_loss: 1.7881e-07\n",
      "Epoch 227/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6346e-05 - val_loss: 2.1079e-04\n",
      "Epoch 228/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.9689e-05 - val_loss: 5.6028e-07\n",
      "Epoch 229/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.8168e-06 - val_loss: 1.3340e-05\n",
      "Epoch 230/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.5618e-05 - val_loss: 0.0026\n",
      "Epoch 231/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.9683e-04 - val_loss: 0.0390\n",
      "Epoch 232/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.1556\n",
      "Epoch 233/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.8203 - val_loss: 1.9311\n",
      "Epoch 234/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 192.1107 - val_loss: 63.2622\n",
      "Epoch 235/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 15.8258 - val_loss: 337.9368\n",
      "Epoch 236/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 20.0040 - val_loss: 0.0012\n",
      "Epoch 237/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 1.7762e-05\n",
      "Epoch 238/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1476e-05 - val_loss: 4.1270e-05\n",
      "Epoch 239/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.5333e-06 - val_loss: 4.8757e-06\n",
      "Epoch 240/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.4001e-06 - val_loss: 9.9421e-06\n",
      "Epoch 241/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2394e-06 - val_loss: 2.2650e-07\n",
      "Epoch 242/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.5095e-06 - val_loss: 3.3021e-06\n",
      "Epoch 243/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4396e-04 - val_loss: 0.0038\n",
      "Epoch 244/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 3.4800e-04\n",
      "Epoch 245/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 246/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0163\n",
      "Epoch 247/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0791\n",
      "Epoch 248/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0061\n",
      "Epoch 249/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 1.8394e-05\n",
      "Epoch 250/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 251/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.1683\n",
      "Epoch 252/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 19.7469\n",
      "Epoch 253/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 384.6128 - val_loss: 7663.9609\n",
      "Epoch 254/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1040.2278 - val_loss: 315.0871\n",
      "Epoch 255/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 39.0015 - val_loss: 0.2569\n",
      "Epoch 256/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2529 - val_loss: 0.0058\n",
      "Epoch 257/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 1.0757e-04\n",
      "Epoch 258/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4833e-05 - val_loss: 7.0214e-06\n",
      "Epoch 259/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9481e-06 - val_loss: 6.5565e-07\n",
      "Epoch 260/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2781e-06 - val_loss: 1.0967e-06\n",
      "Epoch 261/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.0046e-07 - val_loss: 2.0385e-06\n",
      "Epoch 262/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.7796e-07 - val_loss: 6.0797e-07\n",
      "Epoch 263/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4185e-07 - val_loss: 1.2946e-05\n",
      "Epoch 264/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6480e-06 - val_loss: 1.1921e-07\n",
      "Epoch 265/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.4734e-07 - val_loss: 2.4080e-06\n",
      "Epoch 266/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.5323e-07 - val_loss: 3.5763e-07\n",
      "Epoch 267/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9568e-07 - val_loss: 2.2054e-06\n",
      "Epoch 268/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.1132e-06 - val_loss: 2.4915e-06\n",
      "Epoch 269/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.1921e-06 - val_loss: 0.0014\n",
      "Epoch 270/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.9732e-04 - val_loss: 6.0475e-05\n",
      "Epoch 271/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.5734e-05 - val_loss: 7.6547e-04\n",
      "Epoch 272/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6108e-04 - val_loss: 2.3842e-07\n",
      "Epoch 273/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 274/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 1.5199e-05\n",
      "Epoch 275/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8931e-05 - val_loss: 0.0012\n",
      "Epoch 276/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.0847e-05 - val_loss: 6.8712e-05\n",
      "Epoch 277/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2145e-04 - val_loss: 0.0660\n",
      "Epoch 278/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1524 - val_loss: 21.5935\n",
      "Epoch 279/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.1780 - val_loss: 1.3652\n",
      "Epoch 280/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2679 - val_loss: 0.4514\n",
      "Epoch 281/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5637 - val_loss: 38.1983\n",
      "Epoch 282/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 51.3695 - val_loss: 29.6766\n",
      "Epoch 283/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 131.0005 - val_loss: 21.1508\n",
      "Epoch 284/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.8528 - val_loss: 0.5921\n",
      "Epoch 285/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2713 - val_loss: 0.4052\n",
      "Epoch 286/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2139 - val_loss: 2.4847\n",
      "Epoch 287/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.7180 - val_loss: 2.4574\n",
      "Epoch 288/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0107\n",
      "Epoch 289/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2220 - val_loss: 736.4100\n",
      "Epoch 290/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 242.3330 - val_loss: 118.6594\n",
      "Epoch 291/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9631 - val_loss: 2.9608\n",
      "Epoch 292/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 24.8693 - val_loss: 0.6138\n",
      "Epoch 293/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.0867\n",
      "Epoch 294/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6577 - val_loss: 43.0480\n",
      "Epoch 295/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 104.6149 - val_loss: 277.9633\n",
      "Epoch 296/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2057.2457 - val_loss: 13.5889\n",
      "Epoch 297/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7095 - val_loss: 0.0060\n",
      "Epoch 298/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6915e-04 - val_loss: 3.4571e-07\n",
      "Epoch 299/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4840e-07 - val_loss: 2.6226e-07\n",
      "Epoch 300/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.5410e-08 - val_loss: 6.6757e-07\n"
     ]
    }
   ],
   "source": [
    "# model 제작\n",
    "try:\n",
    "    if model != None:\n",
    "        print('model 객체 삭제')\n",
    "        del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = Sequential() # 객체 생성\n",
    "# Dense: 전결합층, 1: 출력노드(뉴런), input_dim=2: 입력 데이터 종류 수\n",
    "# activation='linear': 선형회귀\n",
    "model.add(Dense(10, input_dim=2, activation='linear'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# optimizer='adam': 오차 역전파(weight(기울기), bias(편향) update)차\n",
    "# loss='mse': 손실 측정 함수\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='mse')\n",
    "model.summary() # 네트워크 확인\n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, shuffle=True,\n",
    "                epochs=300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 45488876.0000]) # 값을 반영하여 변경 ★\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "\n",
    "plt.show()\n",
    "# train loss: 하강하면 훈련이 정상적으로 진행되고 있음\n",
    "# val loss: 하강하면 훈련되지 않은 데이터를 대상으로 한 테스트도 정상적으로 진행됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='./Basic3.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7568.0\n",
      "7643.0\n",
      "7718.0\n",
      "7793.0\n",
      "7868.0\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[101, 10], [102, 10], [103, 10], [104, 10], [105, 10]])\n",
    "for i in range(len(x)):  # 실제값 비교 목적으로 산출\n",
    "    print((x[i][0] * x[i][1]) / 2 * 5 * 3 - 7)\n",
    "\n",
    "y = np.array([7568, 7643, 7718, 7793, 7868]) # 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "[[7568.001 ]\n",
      " [7643.001 ]\n",
      " [7718.001 ]\n",
      " [7793.0015]\n",
      " [7868.0015]]\n",
      "x: [101  10], 실제값: 7568, 예측값: 7568.00098, 정제된값: 7568\n",
      "x: [102  10], 실제값: 7643, 예측값: 7643.00098, 정제된값: 7643\n",
      "x: [103  10], 실제값: 7718, 예측값: 7718.00098, 정제된값: 7718\n",
      "x: [104  10], 실제값: 7793, 예측값: 7793.00146, 정제된값: 7793\n",
      "x: [105  10], 실제값: 7868, 예측값: 7868.00146, 정제된값: 7868\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(x) # 모델 사용\n",
    "print(p.shape)\n",
    "print(p)\n",
    "for i in range(len(x)):\n",
    "    fmt = 'x: {0}, 실제값: {1}, 예측값: {2:.5f}, 정제된값: {3:.0f}'\n",
    "    print(fmt.format(x[i], y[i], p[i][0], p[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개선이 이루어지지않으면 Kernel restart를 이용한 초기화 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
